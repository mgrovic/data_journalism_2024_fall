---
title: "lab_04"
author: "Derek Willis"
date: "2024-09-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About this lab

To complete this lab, you need to: \* run existing code as directed (look for **Task**). \* modify existing code as directed (look for **Task**). \* write code in empty codeblocks provided to answer questions included (look for **Q**). \* write out the answer in the form of a complete sentence in the space given (look for **A**).

When you are finished, commit changes and push to your personal GitHub repo, then submit the URL to this document on ELMS.

## Load libraries and establish settings

You'll need to load three packages for this: the tidyverse, lubridate and janitor.

**Task** load these three packages.

```{r}
# Turn off scientific notation
options(scipen=999)

# Load the tidyverse. If you have not installed the tidyverse already, remove the # from the next line and run it first.  
# install.packages('tidyverse')
library(tidyverse)
library(janitor)
library(lubridate)

```

For this lab, we want to investigate spending by the two leading Senate candidates in Maryland during this election, Angela Alsobrooks and Larry Hogan. Our goal is to try and standardize the purpose of the expenditures so that we can compare the two campaigns. We have the data, but it's messy - purpose descriptions are spelled differently and capitalized differently - and we need to clean it up. We'll use a combination of RStudio and OpenRefine to do that.

The basic process here is to start in RStudio, export data so that we can use OpenRefine to clean it up, and then bring it back into RStudio to finish our analysis.

## Load Data

You'll need to load one data set, a CSV file of campaign expenditures located in the data folder called "md_senate_expenses.csv"

**Task** Create a codeblock below, then read the data in and assign it to an appropriate variable name. You'll want to make sure that any date columns are actually date datatypes.

```{r}
# Load the Maryland expenditures data table
md_senate_expenses<- read_csv("data/md_senate_expenses.csv")


glimpse(md_senate_expenses)
```

## Answer questions

**Q1.** You've been assigned to compare the spending priorities of the two campaigns, but they describe their spending differently using the `purpose` column. Using OpenRefine, create a project using the original CSV file, make a copy of the `purpose` column called `purpose_clean` and then standardize it, focusing on the purposes that appear most often or have the largest total amounts. You can transform the data as you want - making all records the same case, for example, to help. The goal is to be able to group together as many similar purpose values, so you can choose to call all transportation-related expenses the same thing.

How do you know when you're done? It's a judgment call, but you should be close to 100 unique values for `purpose_clean`, and maybe even below that number.

Then, when you are done standardizing `purpose_clean`, export it as a new CSV file to your data folder, *giving it a different name* and read it back into RStudio as a new dataframe.

Then, using that `purpose_clean` column, write code to find the largest amounts of spending on categories by both campaigns.

**A1.**

```{r}
md_senate_expenses_cleaned<- read.csv("data/md-senate-expenses-refined.csv")


```
```{r}
md_senate_expenses_cleaned_by_purpose <-md_senate_expenses_cleaned |>
group_by (purpose_clean) |>
summarise( 
  total=sum(amount)) |> 
  arrange(desc(total))

md_senate_expenses_cleaned_by_purpose

```

**Q2.** Let's do some research on the top purposes from A1. Feel free to search the Web to understand those terms better if need be, and then write a description comparing and contrasting the two campaigns' largest categories of spending.

**A2.**
Both campaigns main expense was advertising, as Alsobrooks had 14	contributions for $3639344.50 and Hogan had 21 contributions for 2178145.48 dollars. 
```{r} 
 md_senate_expenses_cleaned |>
  group_by(candidate, purpose_clean) |>
  summarise(contributions=n(),
            amount = sum(amount)) |>
  arrange(desc(amount))


```
**Q3.** Pick one of the top categories for each campaign and write code that shows how that spending has changed over time, if at all. You'll need to use lubridate for this. Write a couple of sentences describing that pattern.

**A3.**
Alsobrooks' advertising spending steadily grew in the months up to April, where it peaked, than went back down. This is most likely due to an election that the campaign was preparing for. 
Hogan's was the same, but peaked in May, a month later than the Alsobrooks campaign. 

```{r}

Advertising_cleaned_over <- md_senate_expenses_cleaned |>
  mutate(date = ymd(date)) |>
  filter(purpose_clean == "Advertising",
         candidate == "Alsobrooks" ) |>
  mutate(month_year = floor_date(date, unit = "month")) |>
  group_by(month_year) |>
  summarise(total_amount = sum(amount)) 
  


(Advertising_cleaned_over)
```
```{r}

Advertising_cleaned_over <- md_senate_expenses_cleaned |>
  mutate(date = ymd(date)) |>
  filter(purpose_clean == "Advertising",
         candidate == "Hogan" ) |>
  mutate(month_year = floor_date(date, unit = "month")) |>
  group_by(month_year) |>
  summarise(total_amount = sum(amount)) 
  


(Advertising_cleaned_over)
```
**Q4.** Which committee has the larger payroll or salary spending so far? How many unique recipients of payroll/staff spending are there for each candidate?

**A4.**
Alsobrooks has the larger staff payroll as Hogan's does not have any data show up. Alsobrooks' is 23 unique recipients and Hogan lists 0!


```{r}

 md_senate_expenses_cleaned |>
 filter(candidate == "Alsobrooks",
      purpose_clean == "Salary"
        ) |>
  group_by(last_name) |>
  summarise(
            amount = sum(amount)) 
  

```
```{r}

 md_senate_expenses_cleaned |>
 filter(candidate == "Hogan",
      purpose_clean == "Salary"
        ) |>
  group_by(last_name) |>
  summarise(
            amount = sum(amount)) 
  

```

**Q5** What's the most interesting story idea you've found in this data?

**A5**
Why the Contribution Refund	was so high (197189.02) 	
